\documentclass{article}
\usepackage{lipsum}

\subsection{History of Large Language Models}

Several researchers in artificial intelligence (AI) have attempted to get computers to interpret visual data since the 1950s. Achieving this objective appeared to be rather simple in the early days of AI. One early development is \textit{ELIZA}, a computer program that enables a machine to engage in natural language conversation, developed by \cite{weizenbaum1966}. ELIZA is regarded as one of the first examples of a natural language model and was a rule-based chatbot created to mimic a conversation with a therapist.

A Japanese engineer named Kunihiko Fukushima was motivated by the findings of \cite{hubel1959} to create the cognitron, one of the first deep neural networks, and the neocognitron, its successor, in the 1970s. \cite{fukushima1969} claimed that he had some success teaching the neocognitron to detect handwritten numbers, but the particular learning strategies he employed did not appear to work well for more difficult visual tasks. However, the neocognitron served as a significant source of inspiration for subsequent deep neural network approaches, such as convolutional neural networks, or ConvNets as most industry participants refer to them.

Neural network applications to problems involving ordered sequences, like words, date back to the 1980s, when recurrent neural networks (RNNs) were introduced \cite{elman1990}. These networks were motivated by theories about how the brain processes sequences. This consecutive processing of a sentence and subsequent brain activations that represent it serve as a loose inspiration for recurrent neural networks. The RNN differs primarily in that its hidden units have extra ``recurrent'' connections; each hidden unit is connected to both the other hidden units and to itself (dashed arrows).

A Swiss research team came up with a solution in the late 1990s: each unit in a recurrent neural network should have a more complicated structure, with unique weights that decide what information can be ``forgotten'' and what can be sent on at the next time step. The more complicated units were dubbed \textit{long short-term memory} (LSTM) units. Although the nomenclature may be perplexing, the idea is that these units enable more ``short-term'' memory to be retained throughout the sentence processing process. Like the ordinary weights in a conventional neural network, the specialized weights are also learned using back-propagation \cite{gers2000}.

When the Internet rose in the 2000s, many researchers began to create large-scale datasets, sometimes referred to as ``web corpora''. Because of their capacity to efficiently handle huge volumes of data, statistical language models (LMs) had largely overtaken symbolic models in the majority of NLP tasks by 2009. Around 2012, neural networks gained popularity in image processing, and these models were then modified for language modeling. Google switched to Neural Machine Translation (NMT) for its translation service in 2016. Sequence-to-sequence (seq2seq) deep LSTM networks were used to accomplish this transformation before the development of transformers.

Google researchers introduced the transformer design in their ground-breaking article, ``Attention Is All You Need,'' at the 2017 NeurIPS conference \cite{Vaswani2017}. By mainly expanding upon the attention mechanism created in 2014, this effort sought to improve the seq2seq technology that was first launched in 2014. BERT was first implemented in 2018 \cite{devlin2019bert} and quickly gained traction. While the original transformer model contains encoder and decoder blocks, BERT utilizes simply the encoder component.

Although the decoder-only model GPT-1 was first presented in 2018 \cite{radford2019}, GPT-2, which was released in 2019 \cite{radford2019}, attracted a lot of interest. GPT-2 was initially suppressed by OpenAI because of worries about its potential for malicious usage. The model was further developed with the release of GPT-3 in 2020 \cite{brown2020language}, but as of 2024, it can only be accessed through an API; there is no way to download and execute it locally. But the introduction of the ChatGPT browser-based interface in 2022 captivated the audience and attracted a lot of media attention. Launched in 2023, GPT-4 was praised for its multimodal capabilities and increased accuracy, which some refer to as the ``holy grail'' \cite{openai2023}. The architecture and number of parameters for GPT-4 have not been revealed by OpenAI.

The quick development of natural language processing is reflected in this evolution, which has produced increasingly complex and powerful language models.

\subsection{The advent of RNN with LSTM and Transformer Architecture with Self Attention} 

Understanding the foundations of deep learning and natural language processing (NLP) is important before exploring self-attention and the transformer. Neural networks are used in the machine learning branch of deep learning to extract relationships and patterns from data. A group of algorithms known as neural networks are made to identify patterns and create connections in data. Besides, NLP is a subfield of AI that studies how people and computers communicate using natural language.

NLP models have historically been created to extract statistical patterns and linguistic structures from large amounts of textual data. By capturing the connections between words, phrases, and sentences, these models hope to produce writing that is both logical and pertinent to its context. NLP has benefited greatly from the emergence of several important models, including decision trees, support vector machines (SVMs), maximum entropy models (MEM) \cite{berger1996}, hidden Markov models (HMM) \cite{rabiner1989}, and n-gram models \cite{jelinek1980}. These models serve as the basis for traditional NLP modeling, propelling developments in text categorization, information extraction, speech recognition, machine translation, and sentiment analysis.

In the past, NLP and computer vision operated as distinct fields within artificial intelligence. However, the fundamental models resulting from these breakthroughs have also found use in the field of computer vision due to the recent developments in LLMs and their application in processing large volumes of data. Because the Self-Attention mechanism and transformer design have a theoretical underpinning, this convergence makes it possible to integrate research efforts in both domains \cite{Vaswani2017}. The development of LLMs based on transformer architecture and the self-attention mechanism has transformed NLP. By expanding the boundaries of natural language understanding, these sophisticated LLMs have changed the field of natural language processing. It is essential to further investigate the topic and gain a thorough grasp of the self-attention mechanism and transformer architecture in order to lead this fascinating wave of LLMs and realize their full potential.

With its particular advantages over the traditional convolutional neural network (CNN) and recurrent neural network (RNN) architectures, the transformer architecture stands out. The model can process all items in parallel by using self-attention, which allows it to dynamically allocate its attention to various input sequence segments. The model's ability to collect long-range dependencies and contextual information is greatly improved by this capability \cite{Vaswani2017}. Furthermore, a review of transformer development shows significant advancements, such as the application of NLP approaches in many fields, the development of hybrid architectures, and the extension of these techniques to computer vision applications \cite{dosovitskiy2020}. The creation of innovative LLMs like GPT \cite{radford2019} (Generative Pre-Trained Transformer) has been made possible by these developments.

\subsection{Limitations of RNNs and LSTMs} 

Recurrent Neural Networks (RNNs) can be categorized into discrete-time and continuous-time variants \cite{grossberg2013}. A defining feature of RNNs is their cyclic connections, allowing the network to update its current state based on both input and previous states \cite{salehinejad2017recent}. In certain applications, fully connected RNNs \cite{elman1990} and selective RNNs \cite{ster2013}, which employ common recurrent cells like sigma cells, have shown promise. However, RNNs struggle to capture long-range dependencies between distant input tokens \cite{ster2013}. Although RNNs are designed to model sequential data, they often struggle with learning long-term dependencies due to issues like vanishing and exploding gradients. Due to these limitations, self-attention mechanisms were introduced as an alternative to traditional RNN-based approaches.

\subsection{How Transformers Revolutionized NLP with Multi-Head Self-Attention}

By employing multiple attention heads and introducing so-called self-attention to substitute RNNs in the encoder and decoder, the Transformer architecture expanded the mechanism \cite{Vaswani2017}. For NMT, and more recently for language modeling \cite{Radford2018} and other downstream tasks \cite{Strubell2018}, this design quickly emerged as the de facto state-of-the-art architecture. The Transformer distributes a token's attention across the entire input sequence multiple times. This mechanism allows the model to intuitively capture various semantic and syntactic attributes. Because of this feature, a field of study has emerged that focuses on the attention mechanisms and interpretation of Transformer-based networks \cite{Raganato2018}. According to new research on machine translation (MT) \cite{Voita2019b}, all attention heads are optional, whereas a small number are specialized for a particular function, such as concentrating on rare words or syntactic dependency relations, and greatly enhance translation performance. However, recent studies have tried to align the mathematical definition of self-attention with the linguistic assumption that attention would be most helpful in a limited local context, such as when translating sentences \cite{Hao2019a}. For example, in order to enhance the focus on local positional patterns, Shaw et al. \cite{Shaw2018} substitute relative position encoding for the Transformer's sinusoidal position encoding. In order to bias the attention weights towards local locations, a number of studies alter the attention formula \cite{Yang2018}. Convolutional modules are used to substitute portions of self-attention, increasing the computational efficiency of the networks as a whole \cite{Wu2019}. In order to avoid redundancy among the many attention heads and to promote local attention patterns, \cite{Cui2019} mask out specific tokens when computing attention. All of these contributions have demonstrated the value of locality and the potential for using lightweight convolutional networks to achieve competitive results with fewer parameters \cite{Wu2019}. Our study focuses exclusively on the original Transformer architecture, investigating the replacement of fixed attention patterns with learnable self-attention mechanisms in the encoder.

\subsection{Therapy Chatbots Built on Pre-Trained LLMs} 

The development of mental health chatbots has evolved significantly over time, incorporating advancements in artificial intelligence and natural language processing. This progression illustrates how advancements in AI and natural language processing have been harnessed to create more effective and empathetic mental health chatbots, improving accessibility and support for individuals seeking mental health assistance.

The use of content analysis and social interaction patterns has been instrumental in identifying and predicting mental health risks. Meanwhile, large language models (LLMs) in recent years, including GPT-4, PaLM, FLAN-T5, and Alpaca show that big pre-trained models can potentially handle a variety of tasks in zero-shot scenarios, or problems that were not encountered during training. Question answering \cite{omar2023chatgpt}, logic reasoning \cite{wei2022finetuned}, machine translation \cite{brants2007large}, and other tasks are examples. Based on hundreds of billions of parameters, several tests have shown that these LLMs have begun to demonstrate the ability to comprehend human common sense beneath natural language and perform appropriate reasoning and inference in accordance with it \cite{bubeck2023sparks}. Among other uses, the ability of LLMs to comprehend human mental health states using natural language is one specific question that has not yet been addressed. Mental health conditions, including anxiety, major depressive disorder, suicidal thoughts, and others \cite{coppersmith2015adhd}, have been the subject of copious research in the last ten years. Social media's real-time nature and archival features frequently aid in reducing retrospective bias. The wealth of social media data also makes it easier to identify, track, and maybe anticipate risk variables over time. In addition to monitoring and identifying threats, social media platforms could be useful avenues for providing communities at risk with timely support \cite{kruzan2022social}.

Mental health issues pose a substantial burden to both individuals and societies across the globe. For example, more than 20 percent of American adults, according to a recent survey, may have at least one mental illness in their lifetime \cite{mha2022state}, and 5.6 percent may have experienced a severe psychotic disease that substantially hinders functioning \cite{nimh2023mental}. The productivity losses from depression and anxiety alone cost the world economy some 1 trillion dollar a year \cite{nami2023mental}. The multi-task arrangement has also been investigated in other studies \cite{benton2017multitask}, including the simultaneous prediction of anxiety and depression \cite{sarkar2022predicting}. These models, however, have limited versatility because they are bound to predefined job sets. From a different angle, the use of chatbots for mental health services has been the subject of additional research \cite{cameron2017towards}. The majority of chatbots are merely rule-based, although they can be strengthened by more sophisticated models \cite{abd-alrazaq2019overview}. Even while research on enabling AI for mental health is expanding, it's crucial to remember that current methods might occasionally introduce bias and even provide users detrimental advice \cite{chen2019can}.

Researchers and practitioners have moved toward larger and more potent language models (e.g., GPT-3 and T5) following the tremendous success of Transformer-based language models like BERT \cite{devlin2019bert} and GPT \cite{Radford2018}. In the meanwhile, scholars have suggested instruction finetuning, a technique that applies different prompts to various activities and datasets. This method directs a model to execute several tasks inside a single, cohesive framework during the training and generation stages \cite{wei2022finetuned}. With tens to hundreds of billions of parameters, these instruction-finetuned LLMs, like GPT-4, PaLM, FLAN-T5, LLaMA, and Alpaca show promising performance on a range of tasks, including question answering, logic reasoning, machine translation \cite{brants2007large}, and more. The potential of these LLMs in health-related sectors has been investigated by researchers \cite{jiang2023health}. For example, \cite{singhal2023towards} improved PaLM-2 on medical domains and obtained 86.5 percent on the MedQA dataset. Likewise, \cite{Wu2019} improved LLaMA on medical publications and shown encouraging outcomes on other biomedical QA datasets. The use of LLMs to address public health issues was investigated by \cite{jo2023understanding}. \cite{jiang2023health} refined a medical language model across a variety of clinical and operational prediction tasks after training it on unstructured clinical notes from the electronic health record. According to their assessment, a model like this can be used in a number of therapeutic activities. The field of mental health has comparatively less work. A few studies investigated LLMs' capacity for emotion reasoning and sentiment processing. Nearer to our research, \cite{lamichhane2023evaluation} and \cite{amin2023affective} evaluated ChatGPT's (GPT-3.5) performance on a variety of classification tasks, including stress, depression, and suicide detection. The findings demonstrated that while ChatGPT offers some promise for use in mental health applications, there is still much space for development, as seen by the at least 5–10 percent accuracy and F1-score performance discrepancies. The potential reasoning ability of GPT-3.5 for reasoning tasks (such as potential stresses) was further assessed by \cite{yang2023evaluations}. Despite the promising results of LLMs in zero-shot settings, most prior studies have primarily focused on this approach and have not extensively explored strategies to further optimize their performance in mental health applications. Despite the promising results of LLMs in zero-shot settings, most prior studies have primarily focused on this approach and have not extensively explored alternative strategies to enhance performance in mental health applications. To bridge this gap, \cite{yang2023mental} introduced Mental-LLaMA, a suite of LLaMA-based models fine-tuned on domain-specific mental health datasets. These models are designed to address a variety of mental health-related tasks, including the detection of depression, suicidal ideation, and psychological stress. However, current research in this area remains limited, with evaluations largely confined to LLaMA and GPT-3.5, indicating a significant opportunity for future work to expand across newer LLM architectures and methodologies.